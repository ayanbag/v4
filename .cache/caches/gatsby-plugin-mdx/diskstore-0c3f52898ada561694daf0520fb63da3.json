{"expireTime":9007200865547474000,"key":"gatsby-plugin-mdx-entire-payload-39124320265dc788a0b3a18e62751304-","val":{"mdast":{"type":"root","children":[{"type":"paragraph","children":[{"type":"strong","children":[{"type":"text","value":"Sckit-learn","position":{"start":{"line":2,"column":3,"offset":3},"end":{"line":2,"column":14,"offset":14},"indent":[]}}],"position":{"start":{"line":2,"column":1,"offset":1},"end":{"line":2,"column":16,"offset":16},"indent":[]}},{"type":"text","value":" is a open source Python library that provides many unsupervised and supervised learning algorithms. It also  implements a range of preprocessing, cross-validation and visualization algorithms using a unified interface","position":{"start":{"line":2,"column":16,"offset":16},"end":{"line":2,"column":234,"offset":234},"indent":[]}}],"position":{"start":{"line":2,"column":1,"offset":1},"end":{"line":2,"column":234,"offset":234},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"Basic example:","position":{"start":{"line":4,"column":1,"offset":236},"end":{"line":4,"column":15,"offset":250},"indent":[]}}],"position":{"start":{"line":4,"column":1,"offset":236},"end":{"line":4,"column":15,"offset":250},"indent":[]}},{"type":"code","lang":"python","meta":null,"value":">>> from sklearn import neighbors, datasets, preprocessing\n>>> from sklearn.model_selection import train_test_split\n>>> from sklearn.metrics import accuracy_score\n>>> iris = datasets.load_iris()\n>>> X, y = iris.data[:, :2], iris.target\n>>> X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=33)\n>>> scaler = preprocessing.StandardScaler().fit(X_train)\n>>> X_train = scaler.transform(X_train)\n>>> X_test = scaler.transform(X_test)\n>>> knn = neighbors.KNeighborsClassifier(n_neighbors=5)\n>>> knn.fit(X_train, y_train)\n>>> y_pred = knn.predict(X_test)>>> accuracy_score(y_test, y_pred)","position":{"start":{"line":5,"column":1,"offset":251},"end":{"line":18,"column":4,"offset":867},"indent":[1,1,1,1,1,1,1,1,1,1,1,1,1]}},{"type":"heading","depth":3,"children":[{"type":"text","value":"Important features of Sckit-learn","position":{"start":{"line":22,"column":5,"offset":875},"end":{"line":22,"column":38,"offset":908},"indent":[]}}],"position":{"start":{"line":22,"column":1,"offset":871},"end":{"line":22,"column":38,"offset":908},"indent":[]}},{"type":"list","ordered":false,"start":null,"spread":false,"children":[{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"Simple and efficient tools for data mining and data analysis. ","position":{"start":{"line":24,"column":3,"offset":912},"end":{"line":24,"column":65,"offset":974},"indent":[]}}],"position":{"start":{"line":24,"column":3,"offset":912},"end":{"line":24,"column":65,"offset":974},"indent":[]}}],"position":{"start":{"line":24,"column":1,"offset":910},"end":{"line":24,"column":65,"offset":974},"indent":[]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"Accessible to everybody and reusable in various contexts.","position":{"start":{"line":25,"column":3,"offset":977},"end":{"line":25,"column":60,"offset":1034},"indent":[]}}],"position":{"start":{"line":25,"column":3,"offset":977},"end":{"line":25,"column":60,"offset":1034},"indent":[]}}],"position":{"start":{"line":25,"column":1,"offset":975},"end":{"line":25,"column":60,"offset":1034},"indent":[]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"Built on the top of NumPy, SciPy, and matplotlib.","position":{"start":{"line":26,"column":3,"offset":1037},"end":{"line":26,"column":52,"offset":1086},"indent":[]}}],"position":{"start":{"line":26,"column":3,"offset":1037},"end":{"line":26,"column":52,"offset":1086},"indent":[]}}],"position":{"start":{"line":26,"column":1,"offset":1035},"end":{"line":26,"column":52,"offset":1086},"indent":[]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"Open source, commercially usable – BSD license","position":{"start":{"line":27,"column":3,"offset":1089},"end":{"line":27,"column":49,"offset":1135},"indent":[]}}],"position":{"start":{"line":27,"column":3,"offset":1089},"end":{"line":27,"column":49,"offset":1135},"indent":[]}}],"position":{"start":{"line":27,"column":1,"offset":1087},"end":{"line":27,"column":49,"offset":1135},"indent":[]}}],"position":{"start":{"line":24,"column":1,"offset":910},"end":{"line":27,"column":49,"offset":1135},"indent":[1,1,1]}},{"type":"heading","depth":3,"children":[{"type":"text","value":"Components of Sckit-learn","position":{"start":{"line":31,"column":5,"offset":1143},"end":{"line":31,"column":30,"offset":1168},"indent":[]}}],"position":{"start":{"line":31,"column":1,"offset":1139},"end":{"line":31,"column":30,"offset":1168},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"Scikit-learn comes loaded with a lot of features. Here are a few of them to help you understand the spread:","position":{"start":{"line":33,"column":1,"offset":1170},"end":{"line":33,"column":108,"offset":1277},"indent":[]}}],"position":{"start":{"line":33,"column":1,"offset":1170},"end":{"line":33,"column":108,"offset":1277},"indent":[]}},{"type":"list","ordered":false,"start":null,"spread":false,"children":[{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"strong","children":[{"type":"text","value":"Supervised Learning algorithms","position":{"start":{"line":35,"column":5,"offset":1283},"end":{"line":35,"column":35,"offset":1313},"indent":[]}}],"position":{"start":{"line":35,"column":3,"offset":1281},"end":{"line":35,"column":37,"offset":1315},"indent":[]}},{"type":"text","value":" : Supervised learning is the machine learning task of learning a function that maps an input to an output based on example input-output pairs. It infers a function from labeled training data consisting of a set of training examples.","position":{"start":{"line":35,"column":37,"offset":1315},"end":{"line":35,"column":270,"offset":1548},"indent":[]}}],"position":{"start":{"line":35,"column":3,"offset":1281},"end":{"line":35,"column":270,"offset":1548},"indent":[]}}],"position":{"start":{"line":35,"column":1,"offset":1279},"end":{"line":35,"column":270,"offset":1548},"indent":[]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"strong","children":[{"type":"text","value":"Unsupervised Learning Algorithms","position":{"start":{"line":36,"column":5,"offset":1553},"end":{"line":36,"column":37,"offset":1585},"indent":[]}}],"position":{"start":{"line":36,"column":3,"offset":1551},"end":{"line":36,"column":39,"offset":1587},"indent":[]}},{"type":"text","value":" : There is a large spread of machine learning algorithms in the offering – starting from clustering, factor analysis, principal component analysis to unsupervised neural networks.","position":{"start":{"line":36,"column":39,"offset":1587},"end":{"line":36,"column":219,"offset":1767},"indent":[]}}],"position":{"start":{"line":36,"column":3,"offset":1551},"end":{"line":36,"column":219,"offset":1767},"indent":[]}}],"position":{"start":{"line":36,"column":1,"offset":1549},"end":{"line":36,"column":219,"offset":1767},"indent":[]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"strong","children":[{"type":"text","value":"Cross-validation","position":{"start":{"line":37,"column":5,"offset":1772},"end":{"line":37,"column":21,"offset":1788},"indent":[]}}],"position":{"start":{"line":37,"column":3,"offset":1770},"end":{"line":37,"column":23,"offset":1790},"indent":[]}},{"type":"text","value":" : These are re-sampling procedure used to evaluate machine learning models on a limited data using sklearn.","position":{"start":{"line":37,"column":23,"offset":1790},"end":{"line":37,"column":131,"offset":1898},"indent":[]}}],"position":{"start":{"line":37,"column":3,"offset":1770},"end":{"line":37,"column":131,"offset":1898},"indent":[]}}],"position":{"start":{"line":37,"column":1,"offset":1768},"end":{"line":37,"column":131,"offset":1898},"indent":[]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"strong","children":[{"type":"text","value":"Feature Extraction","position":{"start":{"line":38,"column":5,"offset":1903},"end":{"line":38,"column":23,"offset":1921},"indent":[]}}],"position":{"start":{"line":38,"column":3,"offset":1901},"end":{"line":38,"column":25,"offset":1923},"indent":[]}},{"type":"text","value":" : Scikit-learn for extracting features from images and text ","position":{"start":{"line":38,"column":25,"offset":1923},"end":{"line":38,"column":86,"offset":1984},"indent":[]}}],"position":{"start":{"line":38,"column":3,"offset":1901},"end":{"line":38,"column":86,"offset":1984},"indent":[]}}],"position":{"start":{"line":38,"column":1,"offset":1899},"end":{"line":38,"column":86,"offset":1984},"indent":[]}}],"position":{"start":{"line":35,"column":1,"offset":1279},"end":{"line":38,"column":86,"offset":1984},"indent":[1,1,1]}},{"type":"heading","depth":3,"children":[{"type":"text","value":"Installation of Sckit-learn","position":{"start":{"line":42,"column":5,"offset":1992},"end":{"line":42,"column":32,"offset":2019},"indent":[]}}],"position":{"start":{"line":42,"column":1,"offset":1988},"end":{"line":42,"column":32,"offset":2019},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"Sckit-learn requires:","position":{"start":{"line":44,"column":1,"offset":2021},"end":{"line":44,"column":22,"offset":2042},"indent":[]}}],"position":{"start":{"line":44,"column":1,"offset":2021},"end":{"line":44,"column":22,"offset":2042},"indent":[]}},{"type":"list","ordered":false,"start":null,"spread":false,"children":[{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"Numpy","position":{"start":{"line":45,"column":3,"offset":2045},"end":{"line":45,"column":8,"offset":2050},"indent":[]}}],"position":{"start":{"line":45,"column":3,"offset":2045},"end":{"line":45,"column":8,"offset":2050},"indent":[]}}],"position":{"start":{"line":45,"column":1,"offset":2043},"end":{"line":45,"column":8,"offset":2050},"indent":[]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"SciPy as its dependencies","position":{"start":{"line":46,"column":3,"offset":2053},"end":{"line":46,"column":28,"offset":2078},"indent":[]}}],"position":{"start":{"line":46,"column":3,"offset":2053},"end":{"line":46,"column":28,"offset":2078},"indent":[]}}],"position":{"start":{"line":46,"column":1,"offset":2051},"end":{"line":46,"column":28,"offset":2078},"indent":[]}}],"position":{"start":{"line":45,"column":1,"offset":2043},"end":{"line":46,"column":28,"offset":2078},"indent":[1]}},{"type":"paragraph","children":[{"type":"text","value":"Before installing Sckit-learn , ensure that ","position":{"start":{"line":48,"column":1,"offset":2080},"end":{"line":48,"column":45,"offset":2124},"indent":[]}},{"type":"strong","children":[{"type":"text","value":"Numpy","position":{"start":{"line":48,"column":47,"offset":2126},"end":{"line":48,"column":52,"offset":2131},"indent":[]}}],"position":{"start":{"line":48,"column":45,"offset":2124},"end":{"line":48,"column":54,"offset":2133},"indent":[]}},{"type":"text","value":" and ","position":{"start":{"line":48,"column":54,"offset":2133},"end":{"line":48,"column":59,"offset":2138},"indent":[]}},{"type":"strong","children":[{"type":"text","value":"SciPy","position":{"start":{"line":48,"column":61,"offset":2140},"end":{"line":48,"column":66,"offset":2145},"indent":[]}}],"position":{"start":{"line":48,"column":59,"offset":2138},"end":{"line":48,"column":68,"offset":2147},"indent":[]}},{"type":"text","value":" is installed in the working directory.\nThe easiest way to install ","position":{"start":{"line":48,"column":68,"offset":2147},"end":{"line":49,"column":28,"offset":2214},"indent":[1]}},{"type":"strong","children":[{"type":"text","value":"Sckit-learn","position":{"start":{"line":49,"column":30,"offset":2216},"end":{"line":49,"column":41,"offset":2227},"indent":[]}}],"position":{"start":{"line":49,"column":28,"offset":2214},"end":{"line":49,"column":43,"offset":2229},"indent":[]}},{"type":"text","value":" is by using ","position":{"start":{"line":49,"column":43,"offset":2229},"end":{"line":49,"column":56,"offset":2242},"indent":[]}},{"type":"inlineCode","value":"pip","position":{"start":{"line":49,"column":56,"offset":2242},"end":{"line":49,"column":65,"offset":2251},"indent":[]}},{"type":"text","value":" ","position":{"start":{"line":49,"column":65,"offset":2251},"end":{"line":49,"column":66,"offset":2252},"indent":[]}}],"position":{"start":{"line":48,"column":1,"offset":2080},"end":{"line":49,"column":66,"offset":2252},"indent":[1]}},{"type":"code","lang":"python","meta":null,"value":"pip install -U scikit-learn","position":{"start":{"line":51,"column":1,"offset":2254},"end":{"line":53,"column":4,"offset":2295},"indent":[1,1]}},{"type":"thematicBreak","position":{"start":{"line":56,"column":1,"offset":2298},"end":{"line":56,"column":4,"offset":2301},"indent":[]}},{"type":"heading","depth":2,"children":[{"type":"text","value":"Loading The Data","position":{"start":{"line":57,"column":4,"offset":2305},"end":{"line":57,"column":20,"offset":2321},"indent":[]}}],"position":{"start":{"line":57,"column":1,"offset":2302},"end":{"line":57,"column":21,"offset":2322},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"Your data needs to be numeric and stored as NumPy arrays or SciPy sparse matrices. Other types that are convertible to numeric arrays, such as Pandas DataFrame, are also acceptable.","position":{"start":{"line":59,"column":1,"offset":2324},"end":{"line":59,"column":182,"offset":2505},"indent":[]}}],"position":{"start":{"line":59,"column":1,"offset":2324},"end":{"line":59,"column":182,"offset":2505},"indent":[]}},{"type":"code","lang":"python","meta":null,"value":">>> import numpy as np\n>>> X = np.random.random((30,8))\n>>> y = np.array(['A','A','B','A','B'])\n>>> X[X < 0.7] = 0","position":{"start":{"line":61,"column":1,"offset":2507},"end":{"line":66,"column":4,"offset":2635},"indent":[1,1,1,1,1]}},{"type":"thematicBreak","position":{"start":{"line":69,"column":1,"offset":2638},"end":{"line":69,"column":4,"offset":2641},"indent":[]}},{"type":"heading","depth":2,"children":[{"type":"text","value":"Training and Testing Data","position":{"start":{"line":70,"column":4,"offset":2645},"end":{"line":70,"column":29,"offset":2670},"indent":[]}}],"position":{"start":{"line":70,"column":1,"offset":2642},"end":{"line":70,"column":29,"offset":2670},"indent":[]}},{"type":"code","lang":"Python","meta":null,"value":">>> from sklearn.model_selection import train_test_split\n>>> X_train, X_test, y_train, y_test = train_test_split(X,Y,random_state=0)","position":{"start":{"line":72,"column":1,"offset":2672},"end":{"line":75,"column":4,"offset":2818},"indent":[1,1,1]}},{"type":"thematicBreak","position":{"start":{"line":78,"column":1,"offset":2821},"end":{"line":78,"column":4,"offset":2824},"indent":[]}},{"type":"heading","depth":2,"children":[{"type":"text","value":"Preprocessing The Data","position":{"start":{"line":79,"column":4,"offset":2828},"end":{"line":79,"column":26,"offset":2850},"indent":[]}}],"position":{"start":{"line":79,"column":1,"offset":2825},"end":{"line":79,"column":26,"offset":2850},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"Data Preprocessing is a step in which data gets transformed or encoded, to bring it in such a state that the machine can easily parse it. In other words, the data now can be easily interpreted by the algorithms.","position":{"start":{"line":81,"column":1,"offset":2852},"end":{"line":81,"column":212,"offset":3063},"indent":[]}}],"position":{"start":{"line":81,"column":1,"offset":2852},"end":{"line":81,"column":212,"offset":3063},"indent":[]}},{"type":"heading","depth":3,"children":[{"type":"text","value":"Standardization","position":{"start":{"line":83,"column":5,"offset":3069},"end":{"line":83,"column":20,"offset":3084},"indent":[]}}],"position":{"start":{"line":83,"column":1,"offset":3065},"end":{"line":83,"column":20,"offset":3084},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"Standardization refers to shifting the distribution of each attribute to have a mean of zero and a standard deviation of one (unit variance).","position":{"start":{"line":85,"column":1,"offset":3086},"end":{"line":85,"column":142,"offset":3227},"indent":[]}}],"position":{"start":{"line":85,"column":1,"offset":3086},"end":{"line":85,"column":142,"offset":3227},"indent":[]}},{"type":"code","lang":"python","meta":null,"value":">>> from sklearn.preprocessing import StandardScaler\n>>> scaler = StandardScaler().fit(X_train)\n>>> standardized_X = scaler.transform(X_train)\n>>> standardized_X_test = scaler.transform(X_test)","position":{"start":{"line":87,"column":1,"offset":3229},"end":{"line":92,"column":4,"offset":3436},"indent":[1,1,1,1,1]}},{"type":"heading","depth":3,"children":[{"type":"text","value":"Normalization","position":{"start":{"line":94,"column":5,"offset":3442},"end":{"line":94,"column":18,"offset":3455},"indent":[]}}],"position":{"start":{"line":94,"column":1,"offset":3438},"end":{"line":94,"column":18,"offset":3455},"indent":[]}},{"type":"code","lang":"python","meta":null,"value":">>> from sklearn.preprocessing import Normalizer\n>>> scaler = Normalizer().fit(X_train)\n>>> normalized_X = scaler.transform(X_train)\n>>> normalized_X_test = scaler.transform(X_test)","position":{"start":{"line":96,"column":1,"offset":3457},"end":{"line":101,"column":4,"offset":3652},"indent":[1,1,1,1,1]}},{"type":"heading","depth":3,"children":[{"type":"text","value":"Binarization","position":{"start":{"line":103,"column":5,"offset":3658},"end":{"line":103,"column":17,"offset":3670},"indent":[]}}],"position":{"start":{"line":103,"column":1,"offset":3654},"end":{"line":103,"column":17,"offset":3670},"indent":[]}},{"type":"code","lang":"python","meta":null,"value":">>> from sklearn.preprocessing import Binarizer\n>>> binarizer = Binarizer(threshold=0.0).fit(X)\n>>> binary_X = binarizer.transform(X)","position":{"start":{"line":105,"column":1,"offset":3672},"end":{"line":109,"column":4,"offset":3819},"indent":[1,1,1,1]}},{"type":"heading","depth":3,"children":[{"type":"text","value":"Encoding Categorical Features","position":{"start":{"line":111,"column":5,"offset":3825},"end":{"line":111,"column":34,"offset":3854},"indent":[]}}],"position":{"start":{"line":111,"column":1,"offset":3821},"end":{"line":111,"column":34,"offset":3854},"indent":[]}},{"type":"code","lang":"python","meta":null,"value":">>> from sklearn.preprocessing import LabelEncoder\n>>> enc = LabelEncoder()\n>>> y = enc.fit_transform(y)py","position":{"start":{"line":113,"column":1,"offset":3856},"end":{"line":117,"column":4,"offset":3976},"indent":[1,1,1,1]}},{"type":"heading","depth":3,"children":[{"type":"text","value":"Imputing Missing Values","position":{"start":{"line":119,"column":5,"offset":3982},"end":{"line":119,"column":28,"offset":4005},"indent":[]}}],"position":{"start":{"line":119,"column":1,"offset":3978},"end":{"line":119,"column":28,"offset":4005},"indent":[]}},{"type":"code","lang":"python","meta":null,"value":">>> from sklearn.preprocessing import Imputer\n>>> imp = Imputer(missing_values=0, strategy='mean', axis=0)\n>>> imp.fit_transform(X_train)","position":{"start":{"line":121,"column":1,"offset":4007},"end":{"line":125,"column":4,"offset":4158},"indent":[1,1,1,1]}},{"type":"heading","depth":3,"children":[{"type":"text","value":"Generating Polynomial Features","position":{"start":{"line":127,"column":5,"offset":4164},"end":{"line":127,"column":35,"offset":4194},"indent":[]}}],"position":{"start":{"line":127,"column":1,"offset":4160},"end":{"line":127,"column":35,"offset":4194},"indent":[]}},{"type":"code","lang":"python","meta":null,"value":">>> from sklearn.preprocessing import PolynomialFeatures\n>>> poly = PolynomialFeatures(5)\n>>> poly.fit_transform(X)","position":{"start":{"line":129,"column":1,"offset":4196},"end":{"line":133,"column":4,"offset":4325},"indent":[1,1,1,1]}},{"type":"heading","depth":2,"children":[{"type":"text","value":"Creating the Model","position":{"start":{"line":137,"column":4,"offset":4332},"end":{"line":137,"column":22,"offset":4350},"indent":[]}}],"position":{"start":{"line":137,"column":1,"offset":4329},"end":{"line":137,"column":22,"offset":4350},"indent":[]}},{"type":"heading","depth":3,"children":[{"type":"text","value":"Supervised Learning Estimators","position":{"start":{"line":139,"column":5,"offset":4356},"end":{"line":139,"column":35,"offset":4386},"indent":[]}}],"position":{"start":{"line":139,"column":1,"offset":4352},"end":{"line":139,"column":35,"offset":4386},"indent":[]}},{"type":"code","lang":"python","meta":null,"value":"Linear Regression\n>>> from sklearn.linear_model import LinearRegression\n>>> lr = LinearRegression(normalize=True)   \n\nSupport Vector Machines (SVM)\n>>> from sklearn.svm import SVC\n>>> svc = SVC(kernel='linear')   \n\nNaive Bayes \n>>> from sklearn.naive_bayes import GaussianNB\n>>> gnb = GaussianNB()   \n\nKNN\n>>> from sklearn import neighbors\n>>> knn = neighbors.KNeighborsClassifier(n_neighbors=5)","position":{"start":{"line":141,"column":1,"offset":4388},"end":{"line":157,"column":4,"offset":4797},"indent":[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]}},{"type":"heading","depth":3,"children":[{"type":"text","value":"Unsupervised Learning Estimators","position":{"start":{"line":159,"column":5,"offset":4803},"end":{"line":159,"column":37,"offset":4835},"indent":[]}}],"position":{"start":{"line":159,"column":1,"offset":4799},"end":{"line":159,"column":37,"offset":4835},"indent":[]}},{"type":"code","lang":"python","meta":null,"value":"Principal Component Analysis (PCA)\n>>> from sklearn.decomposition import PCA\n>>> pca = PCA(n_components=0.95)   \n\nK Means\n>>> from sklearn.cluster import KMeans\n>>> k_means = KMeans(n_clusters=3, random_state=0)","position":{"start":{"line":161,"column":1,"offset":4837},"end":{"line":169,"column":4,"offset":5062},"indent":[1,1,1,1,1,1,1,1]}},{"type":"thematicBreak","position":{"start":{"line":172,"column":1,"offset":5065},"end":{"line":172,"column":4,"offset":5068},"indent":[]}},{"type":"heading","depth":2,"children":[{"type":"text","value":"Model Fitting","position":{"start":{"line":173,"column":4,"offset":5072},"end":{"line":173,"column":17,"offset":5085},"indent":[]}}],"position":{"start":{"line":173,"column":1,"offset":5069},"end":{"line":173,"column":17,"offset":5085},"indent":[]}},{"type":"code","lang":"python","meta":null,"value":"Supervised learning \n>>> lr.fit(X, y)\t\t\t\t\t\t\t# Fit the model to the data\n>>> knn.fit(X_train, y_train)\n>>> svc.fit(X_train, y_train)   \n\nUnsupervised Learning\n>>> k_means.fit(X_train)\t\t\t\t\t# Fit the model to the data\n>>> pca_model = pca.fit_transform(X_train)\t# Fit to data, then transform it","position":{"start":{"line":175,"column":1,"offset":5087},"end":{"line":184,"column":4,"offset":5391},"indent":[1,1,1,1,1,1,1,1,1]}},{"type":"thematicBreak","position":{"start":{"line":187,"column":1,"offset":5394},"end":{"line":187,"column":4,"offset":5397},"indent":[]}},{"type":"heading","depth":2,"children":[{"type":"text","value":"Prediction","position":{"start":{"line":188,"column":4,"offset":5401},"end":{"line":188,"column":14,"offset":5411},"indent":[]}}],"position":{"start":{"line":188,"column":1,"offset":5398},"end":{"line":188,"column":14,"offset":5411},"indent":[]}},{"type":"code","lang":"python","meta":null,"value":"Supervised Estimators\n>>> y_pred =svc.predict(np.random.random((2,5)))\t# Predict labels\n>>> y_pred = lr.predict(X_test)\t\t\t\t\t\t# Predict labels\n>>> y_pred = knn.predict_proba(X_test)   \t\t\t# Estimate probability of a label\n\nUnsupervised Estimators\n>>> y_pred = k_means.predict(X_test)\t\t\t\t# Predict labels in clustering algos","position":{"start":{"line":190,"column":1,"offset":5413},"end":{"line":198,"column":4,"offset":5748},"indent":[1,1,1,1,1,1,1,1]}},{"type":"thematicBreak","position":{"start":{"line":201,"column":1,"offset":5751},"end":{"line":201,"column":4,"offset":5754},"indent":[]}},{"type":"heading","depth":2,"children":[{"type":"text","value":"Evaluating The Model's Performance","position":{"start":{"line":202,"column":4,"offset":5758},"end":{"line":202,"column":38,"offset":5792},"indent":[]}}],"position":{"start":{"line":202,"column":1,"offset":5755},"end":{"line":202,"column":38,"offset":5792},"indent":[]}},{"type":"heading","depth":3,"children":[{"type":"text","value":"Classification Metrics","position":{"start":{"line":204,"column":5,"offset":5798},"end":{"line":204,"column":27,"offset":5820},"indent":[]}}],"position":{"start":{"line":204,"column":1,"offset":5794},"end":{"line":204,"column":27,"offset":5820},"indent":[]}},{"type":"code","lang":"python","meta":null,"value":" Accuracy Score\n >>> knn.score(X_test, y_test)\t\t\t\t\t\t\t# Estimator score method\n >>> from sklearn.metrics import accuracy_score\t\t\t# Metric scoring functions \n >>> accuracy_score(y_test, y_pred)  \n \n Classification Report\n >>> from sklearn.metrics import classification_report\t# Precision, recall, f1-score\n >>> print(classification_report(y_test, y_pred))  \n \n Confusion Matrix\n >>> from sklearn.metrics import confusion_matrix\n >>> print(confusion_matrix(y_test, y_pred))","position":{"start":{"line":206,"column":1,"offset":5822},"end":{"line":219,"column":4,"offset":6306},"indent":[1,1,1,1,1,1,1,1,1,1,1,1,1]}},{"type":"heading","depth":3,"children":[{"type":"text","value":"Regression Metrics","position":{"start":{"line":221,"column":5,"offset":6312},"end":{"line":221,"column":23,"offset":6330},"indent":[]}}],"position":{"start":{"line":221,"column":1,"offset":6308},"end":{"line":221,"column":23,"offset":6330},"indent":[]}},{"type":"code","lang":"python","meta":null,"value":"Mean Absolute Error\n>>> from sklearn.metrics import mean_absolute_error\n>>> y_true = [3, -0.5, 2]\n>>> mean_absolute_error(y_true, y_pred)   \n\nMean Squared Error\n>>> from sklearn.metrics import mean_squared_error\n>>> mean_squared_error(y_test, y_pred)   \n\nR² Score\n>>> from sklearn.metrics import r2_score\n>>> r2_score(y_true, y_pred)","position":{"start":{"line":223,"column":1,"offset":6332},"end":{"line":236,"column":4,"offset":6679},"indent":[1,1,1,1,1,1,1,1,1,1,1,1,1]}},{"type":"heading","depth":3,"children":[{"type":"text","value":"Clustering Metrics","position":{"start":{"line":238,"column":5,"offset":6685},"end":{"line":238,"column":23,"offset":6703},"indent":[]}}],"position":{"start":{"line":238,"column":1,"offset":6681},"end":{"line":238,"column":23,"offset":6703},"indent":[]}},{"type":"code","lang":"python","meta":null,"value":"Adjusted Rand Index\n>>> from sklearn.metrics import adjusted_rand_score\n>>> adjusted_rand_score(y_true, y_pred)    \n\nHomogeneity\n>>> from sklearn.metrics import homogeneity_score\n>>> homogeneity_score(y_true, y_pred)  \n\nV-measure\n>>> from sklearn.metrics import v_measure_score\n>>> metrics.v_measure_score(y_true, y_pred)  ","position":{"start":{"line":240,"column":1,"offset":6705},"end":{"line":252,"column":4,"offset":7042},"indent":[1,1,1,1,1,1,1,1,1,1,1,1]}},{"type":"heading","depth":3,"children":[{"type":"text","value":"Cross-Validation","position":{"start":{"line":254,"column":5,"offset":7048},"end":{"line":254,"column":21,"offset":7064},"indent":[]}}],"position":{"start":{"line":254,"column":1,"offset":7044},"end":{"line":254,"column":21,"offset":7064},"indent":[]}},{"type":"code","lang":"python","meta":null,"value":">>> from sklearn.cross_validation import cross_val_score\n>>> print(cross_val_score(knn, X_train, y_train, cv=4))\n>>> print(cross_val_score(lr, X, y, cv=2))","position":{"start":{"line":256,"column":1,"offset":7066},"end":{"line":260,"column":4,"offset":7235},"indent":[1,1,1,1]}},{"type":"thematicBreak","position":{"start":{"line":263,"column":1,"offset":7238},"end":{"line":263,"column":4,"offset":7241},"indent":[]}},{"type":"heading","depth":2,"children":[{"type":"text","value":"Tuning The Model","position":{"start":{"line":264,"column":4,"offset":7245},"end":{"line":264,"column":20,"offset":7261},"indent":[]}}],"position":{"start":{"line":264,"column":1,"offset":7242},"end":{"line":264,"column":20,"offset":7261},"indent":[]}},{"type":"heading","depth":3,"children":[{"type":"text","value":"Grid Search","position":{"start":{"line":266,"column":5,"offset":7267},"end":{"line":266,"column":16,"offset":7278},"indent":[]}}],"position":{"start":{"line":266,"column":1,"offset":7263},"end":{"line":266,"column":16,"offset":7278},"indent":[]}},{"type":"code","lang":"python","meta":null,"value":">>> from sklearn.grid_search import GridSearchCV\n>>> params = {\"n_neighbors\": np.arange(1,3), \"metric\": [\"euclidean\", \"cityblock\"]}\n>>> grid = GridSearchCV(estimator=knn, param_grid=params)\n>>> grid.fit(X_train, y_train)\n>>> print(grid.best_score_)\n>>> print(grid.best_estimator_.n_neighbors)","position":{"start":{"line":268,"column":1,"offset":7280},"end":{"line":275,"column":4,"offset":7586},"indent":[1,1,1,1,1,1,1]}},{"type":"heading","depth":3,"children":[{"type":"text","value":"Randomized Parameter Optimization","position":{"start":{"line":277,"column":5,"offset":7592},"end":{"line":277,"column":38,"offset":7625},"indent":[]}}],"position":{"start":{"line":277,"column":1,"offset":7588},"end":{"line":277,"column":38,"offset":7625},"indent":[]}},{"type":"code","lang":"python","meta":null,"value":">>> from sklearn.grid_search import RandomizedSearchCV\n>>> params = {\"n_neighbors\": range(1,5), \"weights\": [\"uniform\", \"distance\"]}\n>>> rsearch = RandomizedSearchCV(estimator=knn,param_distributions=params,cv=4,n_iter=8, random_state=5)\n>>> rsearch.fit(X_train, y_train)>>> print(rsearch.best_score_)","position":{"start":{"line":279,"column":1,"offset":7627},"end":{"line":284,"column":4,"offset":7941},"indent":[1,1,1,1,1]}},{"type":"thematicBreak","position":{"start":{"line":287,"column":1,"offset":7944},"end":{"line":287,"column":4,"offset":7947},"indent":[]}},{"type":"heading","depth":2,"children":[{"type":"text","value":"Reference","position":{"start":{"line":288,"column":4,"offset":7951},"end":{"line":288,"column":13,"offset":7960},"indent":[]}}],"position":{"start":{"line":288,"column":1,"offset":7948},"end":{"line":288,"column":13,"offset":7960},"indent":[]}},{"type":"list","ordered":false,"start":null,"spread":false,"children":[{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"link","title":null,"url":"https://www.datacamp.com/courses/topic:machine_learning","children":[{"type":"text","value":"DataCamp","position":{"start":{"line":290,"column":4,"offset":7965},"end":{"line":290,"column":12,"offset":7973},"indent":[]}}],"position":{"start":{"line":290,"column":3,"offset":7964},"end":{"line":290,"column":70,"offset":8031},"indent":[]}}],"position":{"start":{"line":290,"column":3,"offset":7964},"end":{"line":290,"column":70,"offset":8031},"indent":[]}}],"position":{"start":{"line":290,"column":1,"offset":7962},"end":{"line":290,"column":70,"offset":8031},"indent":[]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"link","title":null,"url":"https://machinelearningmastery.com/start-here/#python","children":[{"type":"text","value":"Machine Learning Mastery","position":{"start":{"line":291,"column":4,"offset":8035},"end":{"line":291,"column":28,"offset":8059},"indent":[]}}],"position":{"start":{"line":291,"column":3,"offset":8034},"end":{"line":291,"column":84,"offset":8115},"indent":[]}}],"position":{"start":{"line":291,"column":3,"offset":8034},"end":{"line":291,"column":84,"offset":8115},"indent":[]}}],"position":{"start":{"line":291,"column":1,"offset":8032},"end":{"line":291,"column":84,"offset":8115},"indent":[]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"link","title":null,"url":"https://towardsdatascience.com/scale-standardize-or-normalize-with-scikit-learn-6ccc7d176a02","children":[{"type":"text","value":"TowardsDataScience","position":{"start":{"line":292,"column":4,"offset":8119},"end":{"line":292,"column":22,"offset":8137},"indent":[]}}],"position":{"start":{"line":292,"column":3,"offset":8118},"end":{"line":292,"column":117,"offset":8232},"indent":[]}}],"position":{"start":{"line":292,"column":3,"offset":8118},"end":{"line":292,"column":117,"offset":8232},"indent":[]}}],"position":{"start":{"line":292,"column":1,"offset":8116},"end":{"line":292,"column":117,"offset":8232},"indent":[]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"link","title":null,"url":"https://www.analyticsvidhya.com/blog/2017/09/common-machine-learning-algorithms/","children":[{"type":"text","value":"Analytics Vidya","position":{"start":{"line":293,"column":4,"offset":8236},"end":{"line":293,"column":19,"offset":8251},"indent":[]}}],"position":{"start":{"line":293,"column":3,"offset":8235},"end":{"line":293,"column":102,"offset":8334},"indent":[]}}],"position":{"start":{"line":293,"column":3,"offset":8235},"end":{"line":293,"column":102,"offset":8334},"indent":[]}}],"position":{"start":{"line":293,"column":1,"offset":8233},"end":{"line":293,"column":102,"offset":8334},"indent":[]}}],"position":{"start":{"line":290,"column":1,"offset":7962},"end":{"line":293,"column":102,"offset":8334},"indent":[1,1,1]}},{"type":"thematicBreak","position":{"start":{"line":297,"column":1,"offset":8338},"end":{"line":297,"column":4,"offset":8341},"indent":[]}},{"type":"heading","depth":2,"children":[{"type":"text","value":"Author","position":{"start":{"line":298,"column":4,"offset":8345},"end":{"line":298,"column":10,"offset":8351},"indent":[]}}],"position":{"start":{"line":298,"column":1,"offset":8342},"end":{"line":298,"column":10,"offset":8351},"indent":[]}},{"type":"blockquote","children":[{"type":"paragraph","children":[{"type":"text","value":"Hey, I’m Ayan, a backend software engineer. I write about what I know to help viewers like you. please consider supporting what I do!","position":{"start":{"line":300,"column":2,"offset":8355},"end":{"line":300,"column":135,"offset":8488},"indent":[]}}],"position":{"start":{"line":300,"column":2,"offset":8355},"end":{"line":300,"column":135,"offset":8488},"indent":[]}},{"type":"paragraph","children":[{"type":"link","title":null,"url":"https://ko-fi.com/B0B81M1SZ","children":[{"type":"image","title":null,"url":"https://www.ko-fi.com/img/githubbutton_sm.svg","alt":"ko-fi","position":{"start":{"line":302,"column":3,"offset":8493},"end":{"line":302,"column":58,"offset":8548},"indent":[]}}],"position":{"start":{"line":302,"column":2,"offset":8492},"end":{"line":302,"column":88,"offset":8578},"indent":[]}}],"position":{"start":{"line":302,"column":2,"offset":8492},"end":{"line":302,"column":88,"offset":8578},"indent":[]}}],"position":{"start":{"line":299,"column":1,"offset":8352},"end":{"line":302,"column":88,"offset":8578},"indent":[1,1,1]}},{"type":"export","value":"export const _frontmatter = {\"title\":\"Kickstart to Machine Learning with Sckit-learn\",\"date\":\"2020-04-19T00:00:00.000Z\",\"tags\":[\"Python\",\"Machine Learning\"]}","position":{"start":{"line":306,"column":1,"offset":8582},"end":{"line":306,"column":158,"offset":8739},"indent":[]}}],"position":{"start":{"line":1,"column":1,"offset":0},"end":{"line":306,"column":158,"offset":8739}}},"scopeImports":["import * as React from 'react'"],"scopeIdentifiers":["React"],"body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"Kickstart to Machine Learning with Sckit-learn\",\n  \"date\": \"2020-04-19T00:00:00.000Z\",\n  \"tags\": [\"Python\", \"Machine Learning\"]\n};\n\nvar makeShortcode = function makeShortcode(name) {\n  return function MDXDefaultShortcode(props) {\n    console.warn(\"Component \" + name + \" was not imported, exported, or provided by MDXProvider as global scope\");\n    return mdx(\"div\", props);\n  };\n};\n\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Sckit-learn\"), \" is a open source Python library that provides many unsupervised and supervised learning algorithms. It also  implements a range of preprocessing, cross-validation and visualization algorithms using a unified interface\"), mdx(\"p\", null, \"Basic example:\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \">>> from sklearn import neighbors, datasets, preprocessing\\n>>> from sklearn.model_selection import train_test_split\\n>>> from sklearn.metrics import accuracy_score\\n>>> iris = datasets.load_iris()\\n>>> X, y = iris.data[:, :2], iris.target\\n>>> X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=33)\\n>>> scaler = preprocessing.StandardScaler().fit(X_train)\\n>>> X_train = scaler.transform(X_train)\\n>>> X_test = scaler.transform(X_test)\\n>>> knn = neighbors.KNeighborsClassifier(n_neighbors=5)\\n>>> knn.fit(X_train, y_train)\\n>>> y_pred = knn.predict(X_test)>>> accuracy_score(y_test, y_pred)\\n\")), mdx(\"h3\", null, \"Important features of Sckit-learn\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Simple and efficient tools for data mining and data analysis. \"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Accessible to everybody and reusable in various contexts.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Built on the top of NumPy, SciPy, and matplotlib.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Open source, commercially usable \\u2013 BSD license\")), mdx(\"h3\", null, \"Components of Sckit-learn\"), mdx(\"p\", null, \"Scikit-learn comes loaded with a lot of features. Here are a few of them to help you understand the spread:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"Supervised Learning algorithms\"), \" : Supervised learning is the machine learning task of learning a function that maps an input to an output based on example input-output pairs. It infers a function from labeled training data consisting of a set of training examples.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"Unsupervised Learning Algorithms\"), \" : There is a large spread of machine learning algorithms in the offering \\u2013 starting from clustering, factor analysis, principal component analysis to unsupervised neural networks.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"Cross-validation\"), \" : These are re-sampling procedure used to evaluate machine learning models on a limited data using sklearn.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"Feature Extraction\"), \" : Scikit-learn for extracting features from images and text \")), mdx(\"h3\", null, \"Installation of Sckit-learn\"), mdx(\"p\", null, \"Sckit-learn requires:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Numpy\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"SciPy as its dependencies\")), mdx(\"p\", null, \"Before installing Sckit-learn , ensure that \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Numpy\"), \" and \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"SciPy\"), \" is installed in the working directory.\\nThe easiest way to install \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Sckit-learn\"), \" is by using \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"pip\"), \" \"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"pip install -U scikit-learn\\n\")), mdx(\"hr\", null), mdx(\"h2\", null, \"Loading The Data\"), mdx(\"p\", null, \"Your data needs to be numeric and stored as NumPy arrays or SciPy sparse matrices. Other types that are convertible to numeric arrays, such as Pandas DataFrame, are also acceptable.\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \">>> import numpy as np\\n>>> X = np.random.random((30,8))\\n>>> y = np.array(['A','A','B','A','B'])\\n>>> X[X < 0.7] = 0\\n\")), mdx(\"hr\", null), mdx(\"h2\", null, \"Training and Testing Data\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-Python\"\n  }), \">>> from sklearn.model_selection import train_test_split\\n>>> X_train, X_test, y_train, y_test = train_test_split(X,Y,random_state=0)\\n\")), mdx(\"hr\", null), mdx(\"h2\", null, \"Preprocessing The Data\"), mdx(\"p\", null, \"Data Preprocessing is a step in which data gets transformed or encoded, to bring it in such a state that the machine can easily parse it. In other words, the data now can be easily interpreted by the algorithms.\"), mdx(\"h3\", null, \"Standardization\"), mdx(\"p\", null, \"Standardization refers to shifting the distribution of each attribute to have a mean of zero and a standard deviation of one (unit variance).\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \">>> from sklearn.preprocessing import StandardScaler\\n>>> scaler = StandardScaler().fit(X_train)\\n>>> standardized_X = scaler.transform(X_train)\\n>>> standardized_X_test = scaler.transform(X_test)\\n\")), mdx(\"h3\", null, \"Normalization\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \">>> from sklearn.preprocessing import Normalizer\\n>>> scaler = Normalizer().fit(X_train)\\n>>> normalized_X = scaler.transform(X_train)\\n>>> normalized_X_test = scaler.transform(X_test)\\n\")), mdx(\"h3\", null, \"Binarization\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \">>> from sklearn.preprocessing import Binarizer\\n>>> binarizer = Binarizer(threshold=0.0).fit(X)\\n>>> binary_X = binarizer.transform(X)\\n\")), mdx(\"h3\", null, \"Encoding Categorical Features\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \">>> from sklearn.preprocessing import LabelEncoder\\n>>> enc = LabelEncoder()\\n>>> y = enc.fit_transform(y)py\\n\")), mdx(\"h3\", null, \"Imputing Missing Values\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \">>> from sklearn.preprocessing import Imputer\\n>>> imp = Imputer(missing_values=0, strategy='mean', axis=0)\\n>>> imp.fit_transform(X_train)\\n\")), mdx(\"h3\", null, \"Generating Polynomial Features\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \">>> from sklearn.preprocessing import PolynomialFeatures\\n>>> poly = PolynomialFeatures(5)\\n>>> poly.fit_transform(X)\\n\")), mdx(\"h2\", null, \"Creating the Model\"), mdx(\"h3\", null, \"Supervised Learning Estimators\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"Linear Regression\\n>>> from sklearn.linear_model import LinearRegression\\n>>> lr = LinearRegression(normalize=True)   \\n\\nSupport Vector Machines (SVM)\\n>>> from sklearn.svm import SVC\\n>>> svc = SVC(kernel='linear')   \\n\\nNaive Bayes \\n>>> from sklearn.naive_bayes import GaussianNB\\n>>> gnb = GaussianNB()   \\n\\nKNN\\n>>> from sklearn import neighbors\\n>>> knn = neighbors.KNeighborsClassifier(n_neighbors=5)\\n\")), mdx(\"h3\", null, \"Unsupervised Learning Estimators\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"Principal Component Analysis (PCA)\\n>>> from sklearn.decomposition import PCA\\n>>> pca = PCA(n_components=0.95)   \\n\\nK Means\\n>>> from sklearn.cluster import KMeans\\n>>> k_means = KMeans(n_clusters=3, random_state=0)\\n\")), mdx(\"hr\", null), mdx(\"h2\", null, \"Model Fitting\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"Supervised learning \\n>>> lr.fit(X, y)                            # Fit the model to the data\\n>>> knn.fit(X_train, y_train)\\n>>> svc.fit(X_train, y_train)   \\n\\nUnsupervised Learning\\n>>> k_means.fit(X_train)                    # Fit the model to the data\\n>>> pca_model = pca.fit_transform(X_train)  # Fit to data, then transform it\\n\")), mdx(\"hr\", null), mdx(\"h2\", null, \"Prediction\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"Supervised Estimators\\n>>> y_pred =svc.predict(np.random.random((2,5)))    # Predict labels\\n>>> y_pred = lr.predict(X_test)                     # Predict labels\\n>>> y_pred = knn.predict_proba(X_test)              # Estimate probability of a label\\n\\nUnsupervised Estimators\\n>>> y_pred = k_means.predict(X_test)                # Predict labels in clustering algos\\n\")), mdx(\"hr\", null), mdx(\"h2\", null, \"Evaluating The Model's Performance\"), mdx(\"h3\", null, \"Classification Metrics\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \" Accuracy Score\\n >>> knn.score(X_test, y_test)                          # Estimator score method\\n >>> from sklearn.metrics import accuracy_score         # Metric scoring functions \\n >>> accuracy_score(y_test, y_pred)  \\n \\n Classification Report\\n >>> from sklearn.metrics import classification_report  # Precision, recall, f1-score\\n >>> print(classification_report(y_test, y_pred))  \\n \\n Confusion Matrix\\n >>> from sklearn.metrics import confusion_matrix\\n >>> print(confusion_matrix(y_test, y_pred))\\n\")), mdx(\"h3\", null, \"Regression Metrics\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"Mean Absolute Error\\n>>> from sklearn.metrics import mean_absolute_error\\n>>> y_true = [3, -0.5, 2]\\n>>> mean_absolute_error(y_true, y_pred)   \\n\\nMean Squared Error\\n>>> from sklearn.metrics import mean_squared_error\\n>>> mean_squared_error(y_test, y_pred)   \\n\\nR\\xB2 Score\\n>>> from sklearn.metrics import r2_score\\n>>> r2_score(y_true, y_pred)\\n\")), mdx(\"h3\", null, \"Clustering Metrics\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"Adjusted Rand Index\\n>>> from sklearn.metrics import adjusted_rand_score\\n>>> adjusted_rand_score(y_true, y_pred)    \\n\\nHomogeneity\\n>>> from sklearn.metrics import homogeneity_score\\n>>> homogeneity_score(y_true, y_pred)  \\n\\nV-measure\\n>>> from sklearn.metrics import v_measure_score\\n>>> metrics.v_measure_score(y_true, y_pred)  \\n\")), mdx(\"h3\", null, \"Cross-Validation\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \">>> from sklearn.cross_validation import cross_val_score\\n>>> print(cross_val_score(knn, X_train, y_train, cv=4))\\n>>> print(cross_val_score(lr, X, y, cv=2))\\n\")), mdx(\"hr\", null), mdx(\"h2\", null, \"Tuning The Model\"), mdx(\"h3\", null, \"Grid Search\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \">>> from sklearn.grid_search import GridSearchCV\\n>>> params = {\\\"n_neighbors\\\": np.arange(1,3), \\\"metric\\\": [\\\"euclidean\\\", \\\"cityblock\\\"]}\\n>>> grid = GridSearchCV(estimator=knn, param_grid=params)\\n>>> grid.fit(X_train, y_train)\\n>>> print(grid.best_score_)\\n>>> print(grid.best_estimator_.n_neighbors)\\n\")), mdx(\"h3\", null, \"Randomized Parameter Optimization\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \">>> from sklearn.grid_search import RandomizedSearchCV\\n>>> params = {\\\"n_neighbors\\\": range(1,5), \\\"weights\\\": [\\\"uniform\\\", \\\"distance\\\"]}\\n>>> rsearch = RandomizedSearchCV(estimator=knn,param_distributions=params,cv=4,n_iter=8, random_state=5)\\n>>> rsearch.fit(X_train, y_train)>>> print(rsearch.best_score_)\\n\")), mdx(\"hr\", null), mdx(\"h2\", null, \"Reference\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", _extends({\n    parentName: \"li\"\n  }, {\n    \"href\": \"https://www.datacamp.com/courses/topic:machine_learning\"\n  }), \"DataCamp\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", _extends({\n    parentName: \"li\"\n  }, {\n    \"href\": \"https://machinelearningmastery.com/start-here/#python\"\n  }), \"Machine Learning Mastery\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", _extends({\n    parentName: \"li\"\n  }, {\n    \"href\": \"https://towardsdatascience.com/scale-standardize-or-normalize-with-scikit-learn-6ccc7d176a02\"\n  }), \"TowardsDataScience\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", _extends({\n    parentName: \"li\"\n  }, {\n    \"href\": \"https://www.analyticsvidhya.com/blog/2017/09/common-machine-learning-algorithms/\"\n  }), \"Analytics Vidya\"))), mdx(\"hr\", null), mdx(\"h2\", null, \"Author\"), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"Hey, I\\u2019m Ayan, a backend software engineer. I write about what I know to help viewers like you. please consider supporting what I do!\"), mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://ko-fi.com/B0B81M1SZ\"\n  }), mdx(\"img\", _extends({\n    parentName: \"a\"\n  }, {\n    \"src\": \"https://www.ko-fi.com/img/githubbutton_sm.svg\",\n    \"alt\": \"ko-fi\"\n  }))))));\n}\n;\nMDXContent.isMDXComponent = true;","rawMDXOutput":"/* @jsx mdx */\nimport { mdx } from '@mdx-js/react';\n/* @jsx mdx */\n\nexport const _frontmatter = {\n  \"title\": \"Kickstart to Machine Learning with Sckit-learn\",\n  \"date\": \"2020-04-19T00:00:00.000Z\",\n  \"tags\": [\"Python\", \"Machine Learning\"]\n};\nconst makeShortcode = name => function MDXDefaultShortcode(props) {\n  console.warn(\"Component \" + name + \" was not imported, exported, or provided by MDXProvider as global scope\")\n  return <div {...props}/>\n};\n\nconst layoutProps = {\n  _frontmatter\n};\nconst MDXLayout = \"wrapper\"\nexport default function MDXContent({\n  components,\n  ...props\n}) {\n  return <MDXLayout {...layoutProps} {...props} components={components} mdxType=\"MDXLayout\">\n    <p><strong parentName=\"p\">{`Sckit-learn`}</strong>{` is a open source Python library that provides many unsupervised and supervised learning algorithms. It also  implements a range of preprocessing, cross-validation and visualization algorithms using a unified interface`}</p>\n    <p>{`Basic example:`}</p>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`>>> from sklearn import neighbors, datasets, preprocessing\n>>> from sklearn.model_selection import train_test_split\n>>> from sklearn.metrics import accuracy_score\n>>> iris = datasets.load_iris()\n>>> X, y = iris.data[:, :2], iris.target\n>>> X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=33)\n>>> scaler = preprocessing.StandardScaler().fit(X_train)\n>>> X_train = scaler.transform(X_train)\n>>> X_test = scaler.transform(X_test)\n>>> knn = neighbors.KNeighborsClassifier(n_neighbors=5)\n>>> knn.fit(X_train, y_train)\n>>> y_pred = knn.predict(X_test)>>> accuracy_score(y_test, y_pred)\n`}</code></pre>\n    <h3>{`Important features of Sckit-learn`}</h3>\n    <ul>\n      <li parentName=\"ul\">{`Simple and efficient tools for data mining and data analysis. `}</li>\n      <li parentName=\"ul\">{`Accessible to everybody and reusable in various contexts.`}</li>\n      <li parentName=\"ul\">{`Built on the top of NumPy, SciPy, and matplotlib.`}</li>\n      <li parentName=\"ul\">{`Open source, commercially usable – BSD license`}</li>\n    </ul>\n    <h3>{`Components of Sckit-learn`}</h3>\n    <p>{`Scikit-learn comes loaded with a lot of features. Here are a few of them to help you understand the spread:`}</p>\n    <ul>\n      <li parentName=\"ul\"><strong parentName=\"li\">{`Supervised Learning algorithms`}</strong>{` : Supervised learning is the machine learning task of learning a function that maps an input to an output based on example input-output pairs. It infers a function from labeled training data consisting of a set of training examples.`}</li>\n      <li parentName=\"ul\"><strong parentName=\"li\">{`Unsupervised Learning Algorithms`}</strong>{` : There is a large spread of machine learning algorithms in the offering – starting from clustering, factor analysis, principal component analysis to unsupervised neural networks.`}</li>\n      <li parentName=\"ul\"><strong parentName=\"li\">{`Cross-validation`}</strong>{` : These are re-sampling procedure used to evaluate machine learning models on a limited data using sklearn.`}</li>\n      <li parentName=\"ul\"><strong parentName=\"li\">{`Feature Extraction`}</strong>{` : Scikit-learn for extracting features from images and text `}</li>\n    </ul>\n    <h3>{`Installation of Sckit-learn`}</h3>\n    <p>{`Sckit-learn requires:`}</p>\n    <ul>\n      <li parentName=\"ul\">{`Numpy`}</li>\n      <li parentName=\"ul\">{`SciPy as its dependencies`}</li>\n    </ul>\n    <p>{`Before installing Sckit-learn , ensure that `}<strong parentName=\"p\">{`Numpy`}</strong>{` and `}<strong parentName=\"p\">{`SciPy`}</strong>{` is installed in the working directory.\nThe easiest way to install `}<strong parentName=\"p\">{`Sckit-learn`}</strong>{` is by using `}<inlineCode parentName=\"p\">{`pip`}</inlineCode>{` `}</p>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`pip install -U scikit-learn\n`}</code></pre>\n    <hr></hr>\n    <h2>{`Loading The Data`}</h2>\n    <p>{`Your data needs to be numeric and stored as NumPy arrays or SciPy sparse matrices. Other types that are convertible to numeric arrays, such as Pandas DataFrame, are also acceptable.`}</p>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`>>> import numpy as np\n>>> X = np.random.random((30,8))\n>>> y = np.array(['A','A','B','A','B'])\n>>> X[X < 0.7] = 0\n`}</code></pre>\n    <hr></hr>\n    <h2>{`Training and Testing Data`}</h2>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-Python\"\n      }}>{`>>> from sklearn.model_selection import train_test_split\n>>> X_train, X_test, y_train, y_test = train_test_split(X,Y,random_state=0)\n`}</code></pre>\n    <hr></hr>\n    <h2>{`Preprocessing The Data`}</h2>\n    <p>{`Data Preprocessing is a step in which data gets transformed or encoded, to bring it in such a state that the machine can easily parse it. In other words, the data now can be easily interpreted by the algorithms.`}</p>\n    <h3>{`Standardization`}</h3>\n    <p>{`Standardization refers to shifting the distribution of each attribute to have a mean of zero and a standard deviation of one (unit variance).`}</p>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`>>> from sklearn.preprocessing import StandardScaler\n>>> scaler = StandardScaler().fit(X_train)\n>>> standardized_X = scaler.transform(X_train)\n>>> standardized_X_test = scaler.transform(X_test)\n`}</code></pre>\n    <h3>{`Normalization`}</h3>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`>>> from sklearn.preprocessing import Normalizer\n>>> scaler = Normalizer().fit(X_train)\n>>> normalized_X = scaler.transform(X_train)\n>>> normalized_X_test = scaler.transform(X_test)\n`}</code></pre>\n    <h3>{`Binarization`}</h3>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`>>> from sklearn.preprocessing import Binarizer\n>>> binarizer = Binarizer(threshold=0.0).fit(X)\n>>> binary_X = binarizer.transform(X)\n`}</code></pre>\n    <h3>{`Encoding Categorical Features`}</h3>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`>>> from sklearn.preprocessing import LabelEncoder\n>>> enc = LabelEncoder()\n>>> y = enc.fit_transform(y)py\n`}</code></pre>\n    <h3>{`Imputing Missing Values`}</h3>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`>>> from sklearn.preprocessing import Imputer\n>>> imp = Imputer(missing_values=0, strategy='mean', axis=0)\n>>> imp.fit_transform(X_train)\n`}</code></pre>\n    <h3>{`Generating Polynomial Features`}</h3>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`>>> from sklearn.preprocessing import PolynomialFeatures\n>>> poly = PolynomialFeatures(5)\n>>> poly.fit_transform(X)\n`}</code></pre>\n    <h2>{`Creating the Model`}</h2>\n    <h3>{`Supervised Learning Estimators`}</h3>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`Linear Regression\n>>> from sklearn.linear_model import LinearRegression\n>>> lr = LinearRegression(normalize=True)   \n\nSupport Vector Machines (SVM)\n>>> from sklearn.svm import SVC\n>>> svc = SVC(kernel='linear')   \n\nNaive Bayes \n>>> from sklearn.naive_bayes import GaussianNB\n>>> gnb = GaussianNB()   \n\nKNN\n>>> from sklearn import neighbors\n>>> knn = neighbors.KNeighborsClassifier(n_neighbors=5)\n`}</code></pre>\n    <h3>{`Unsupervised Learning Estimators`}</h3>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`Principal Component Analysis (PCA)\n>>> from sklearn.decomposition import PCA\n>>> pca = PCA(n_components=0.95)   \n\nK Means\n>>> from sklearn.cluster import KMeans\n>>> k_means = KMeans(n_clusters=3, random_state=0)\n`}</code></pre>\n    <hr></hr>\n    <h2>{`Model Fitting`}</h2>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`Supervised learning \n>>> lr.fit(X, y)                            # Fit the model to the data\n>>> knn.fit(X_train, y_train)\n>>> svc.fit(X_train, y_train)   \n\nUnsupervised Learning\n>>> k_means.fit(X_train)                    # Fit the model to the data\n>>> pca_model = pca.fit_transform(X_train)  # Fit to data, then transform it\n`}</code></pre>\n    <hr></hr>\n    <h2>{`Prediction`}</h2>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`Supervised Estimators\n>>> y_pred =svc.predict(np.random.random((2,5)))    # Predict labels\n>>> y_pred = lr.predict(X_test)                     # Predict labels\n>>> y_pred = knn.predict_proba(X_test)              # Estimate probability of a label\n\nUnsupervised Estimators\n>>> y_pred = k_means.predict(X_test)                # Predict labels in clustering algos\n`}</code></pre>\n    <hr></hr>\n    <h2>{`Evaluating The Model's Performance`}</h2>\n    <h3>{`Classification Metrics`}</h3>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{` Accuracy Score\n >>> knn.score(X_test, y_test)                          # Estimator score method\n >>> from sklearn.metrics import accuracy_score         # Metric scoring functions \n >>> accuracy_score(y_test, y_pred)  \n \n Classification Report\n >>> from sklearn.metrics import classification_report  # Precision, recall, f1-score\n >>> print(classification_report(y_test, y_pred))  \n \n Confusion Matrix\n >>> from sklearn.metrics import confusion_matrix\n >>> print(confusion_matrix(y_test, y_pred))\n`}</code></pre>\n    <h3>{`Regression Metrics`}</h3>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`Mean Absolute Error\n>>> from sklearn.metrics import mean_absolute_error\n>>> y_true = [3, -0.5, 2]\n>>> mean_absolute_error(y_true, y_pred)   \n\nMean Squared Error\n>>> from sklearn.metrics import mean_squared_error\n>>> mean_squared_error(y_test, y_pred)   \n\nR² Score\n>>> from sklearn.metrics import r2_score\n>>> r2_score(y_true, y_pred)\n`}</code></pre>\n    <h3>{`Clustering Metrics`}</h3>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`Adjusted Rand Index\n>>> from sklearn.metrics import adjusted_rand_score\n>>> adjusted_rand_score(y_true, y_pred)    \n\nHomogeneity\n>>> from sklearn.metrics import homogeneity_score\n>>> homogeneity_score(y_true, y_pred)  \n\nV-measure\n>>> from sklearn.metrics import v_measure_score\n>>> metrics.v_measure_score(y_true, y_pred)  \n`}</code></pre>\n    <h3>{`Cross-Validation`}</h3>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`>>> from sklearn.cross_validation import cross_val_score\n>>> print(cross_val_score(knn, X_train, y_train, cv=4))\n>>> print(cross_val_score(lr, X, y, cv=2))\n`}</code></pre>\n    <hr></hr>\n    <h2>{`Tuning The Model`}</h2>\n    <h3>{`Grid Search`}</h3>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`>>> from sklearn.grid_search import GridSearchCV\n>>> params = {\"n_neighbors\": np.arange(1,3), \"metric\": [\"euclidean\", \"cityblock\"]}\n>>> grid = GridSearchCV(estimator=knn, param_grid=params)\n>>> grid.fit(X_train, y_train)\n>>> print(grid.best_score_)\n>>> print(grid.best_estimator_.n_neighbors)\n`}</code></pre>\n    <h3>{`Randomized Parameter Optimization`}</h3>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`>>> from sklearn.grid_search import RandomizedSearchCV\n>>> params = {\"n_neighbors\": range(1,5), \"weights\": [\"uniform\", \"distance\"]}\n>>> rsearch = RandomizedSearchCV(estimator=knn,param_distributions=params,cv=4,n_iter=8, random_state=5)\n>>> rsearch.fit(X_train, y_train)>>> print(rsearch.best_score_)\n`}</code></pre>\n    <hr></hr>\n    <h2>{`Reference`}</h2>\n    <ul>\n      <li parentName=\"ul\"><a parentName=\"li\" {...{\n          \"href\": \"https://www.datacamp.com/courses/topic:machine_learning\"\n        }}>{`DataCamp`}</a></li>\n      <li parentName=\"ul\"><a parentName=\"li\" {...{\n          \"href\": \"https://machinelearningmastery.com/start-here/#python\"\n        }}>{`Machine Learning Mastery`}</a></li>\n      <li parentName=\"ul\"><a parentName=\"li\" {...{\n          \"href\": \"https://towardsdatascience.com/scale-standardize-or-normalize-with-scikit-learn-6ccc7d176a02\"\n        }}>{`TowardsDataScience`}</a></li>\n      <li parentName=\"ul\"><a parentName=\"li\" {...{\n          \"href\": \"https://www.analyticsvidhya.com/blog/2017/09/common-machine-learning-algorithms/\"\n        }}>{`Analytics Vidya`}</a></li>\n    </ul>\n    <hr></hr>\n    <h2>{`Author`}</h2>\n    <blockquote>\n      <p parentName=\"blockquote\">{`Hey, I’m Ayan, a backend software engineer. I write about what I know to help viewers like you. please consider supporting what I do!`}</p>\n      <p parentName=\"blockquote\"><a parentName=\"p\" {...{\n          \"href\": \"https://ko-fi.com/B0B81M1SZ\"\n        }}><img parentName=\"a\" {...{\n            \"src\": \"https://www.ko-fi.com/img/githubbutton_sm.svg\",\n            \"alt\": \"ko-fi\"\n          }}></img></a></p>\n    </blockquote>\n\n    </MDXLayout>;\n}\n\n;\nMDXContent.isMDXComponent = true;"}}